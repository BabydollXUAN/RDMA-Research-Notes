## 我的Thinking

Intra-DC流量 极低延迟（~10µs级RTT），对吞吐量敏感。Inter-DC流量高延迟（~10ms-60ms级RTT），受限于光速传播延迟（Latency-bound），BDP（带宽时延积）巨大 。还需要考虑公平性问题和丢包问题。
统一的（One-Stop）协议，能够同时满足这两类流量的需求。
Uno强制统一反应粒度 。UnoLB 决定采用“子流” (Subflow) 策略。利用现代网络的多路径特性，把大流量拆散，并行传输 。切块并采用校验码。
结合了 **纠删码 (Erasure Coding)** 和 **动态重路由**。
如果信息足够，纠删码可以通过一定量的信息还原。如果信息不够，出现Time out或者NACK报错，动态重路由采取策略是改变Source Port或者换一条已到达数据包的路径走。
数据包进入物理队列，同时幽灵队列计数器增加-> 幽灵队列“满”时，提前标记ECN。幽灵队列的特点是队列排出速度慢，更有可能提前慢，起到预测作用。
无标记 -> **加窗 (+)**
有标记 + 低延迟 -> **微量减窗 (-)** (幽灵队列起作用)
有标记 + 高延迟 -> **大幅减窗 (--)** (物理队列堵了)
吞吐骤降 -> **重置窗口 (Reset)** (Quick Adapt触发)

## **流量共存带来的异构性挑战**
## `uint64_t`

### 第一阶段：拆解这个“恐怖”的名字

把 `uint64_t` 想象成一个贴在盒子上的标签。我们把这个标签剪开，看看每一部分代表什么：

1. **`int` (Integer，整数)**：
    
    - 这意味着这个盒子里只能装**整数**。
        
    - 比如：1, 50, 10000。
        
    - _不能装：_ 1.5, 3.14, 或者 "Hello"。
        
    - **费曼直觉**：就像数羊。你只能数 1 只羊、2 只羊，不能数半只羊。
        
2. **`u` (Unsigned，无符号)**：
    
    - 这是关键！在计算机里，“有符号”意味着可以有正号（+）也可以有负号（-）。
        
    - “无符号”（Unsigned）意味着**没有负号**。
        
    - **费曼直觉**：这就像是现实生活中的“距离”或“数量”。你不可能跑了“-5公里”，也不可能口袋里有“-10个苹果”。**它永远是从 0 开始的非负数。**
        
3. **`64` (64-bit，64位)**：
    
    - 这代表盒子的大小（容量）。
        
    - **费曼直觉**：这是我们要重点讲的地方（见下一阶段）。
        
4. **`_t` (Type，类型)**：
    
    - 这是 C/C++ 语言的一个习惯后缀，意思是“这是一个标准定义的数据类型”。你可以直接忽略它，它就像名字后面的“先生”或“女士”一样，只是个称呼。
        

**总结第一阶段**：`uint64_t` 就是一个**“专门用来装非负整数的、超大容量的盒子”**。

---

### 第二阶段：盒子到底有多大？（类比法）

为了理解 `64` 到底意味着什么，我们需要对比一下它的“小兄弟”们。计算机里是用二进制（0和1）来存数的，位数越多，能存的数就越大。

想象我们在准备一次旅行，需要带一些钱（数字）：

- **`uint8_t` (8位) —— 火柴盒**
    
    - **容量**：0 到 255。
        
    - **用途**：适合存人的年龄、月份、或者考卷的分数。
        
    - _限制_：如果你想存这种“今年的天数（365）”，火柴盒就塞爆了（溢出）。
        
- **`uint32_t` (32位) —— 运钞车**
    
    - 这是过去几十年最常用的类型。
        
    - **容量**：0 到 4,294,967,295（约 42 亿）。
        
    - **用途**：适合存银行卡余额、网站的访问量。
        
    - _限制_：虽然看起来很大，但如果你要计算全世界的人口（70亿+），运钞车也装不下了。
        
- **`uint64_t` (64位) —— 超级巨型货轮**
    
    - 这就是我们要讲的主角。
        
    - **容量**：0 到 $18,446,744,073,709,551,615$（约 1844 亿亿）。
        
    - **费曼直觉**：这个数字大到人类的大脑无法直观处理。让我们换个方式看：
        
    - **如果每秒钟数 1 个数：**
        
        - 数完 `uint32_t` (42亿) 需要 **136 年**。
            
        - 数完 `uint64_t` 需要 **5850 亿年**。（宇宙的年龄才 138 亿年！）
            

---

### 第三阶段：为什么我们在网络模拟（如 Uno）中需要它？

回到你之前的上下文（Uno 论文和 `htsim` 仿真器）。你可能会问：“既然 32 位的运钞车已经能装 42 亿了，为什么还需要 64 位的货轮？”

这就涉及到了**速度**和**积累**。

**场景案例：网络流量计数器**

假设你在模拟一个数据中心，你的任务是统计“有多少字节的数据流过了这根网线”。

1. **现代网速**：假设网速是 100 Gbps（每秒 100 亿比特，约 125 亿字节）。
    
2. **使用 `uint32_t` (32位)**：
    
    - 上限是 42 亿字节。
        
    - 以 100 Gbps 的速度，只需 **0.34 秒**，计数器就会达到上限，然后归零（这叫“溢出”）。
        
    - _结果_：你的统计数据会完全乱套，你根本不知道到底传了多少数据。
        
3. **使用 `uint64_t` (64位)**：
    
    - 上限是 1844 亿亿字节。
        
    - 以 100 Gbps 的速度，需要 **400 多年** 才会溢出。
        
    - _结果_：你可以放心地让模拟跑上几天几夜，绝对不用担心计数器不够用。
        

### 费曼式的最终总结

你可以这样向别人介绍 `uint64_t`：

> “想象一下汽车的里程表。
> 
> - 普通的里程表（32位）如果只能显示到 42 公里就归零了，那它在高速公路上毫无用处。
>     
> - `uint64_t` 就像一个**超级里程表**，它的数字大到即使这辆车以光速开一辈子，里程表也不会转到底。
>     
> 
> 当我们需要在电脑里记录那些**永远不为负数**、且**可能累积得极其巨大**的数字（比如网络传输的总字节数、内存地址、或者极高精度的时间戳）时，我们就用 `uint64_t`。”



## ECN标记
我们可以把网络传输想象成**你在给远方的朋友寄信**，而路由器（交换机）就是中间的**邮局**。

我们将分三个阶段来理解：**粗暴的旧时代**、**文明的新时代**，以及**ECN 到底长什么样**。

---

### 第一阶段：没有 ECN 的“粗暴旧时代” (Packet Drop)

在 ECN 发明之前，网络拥塞的处理方式非常简单粗暴。

想象一下：你是个写信狂魔（发送端），拼命给朋友写信。中间经过一个邮局（路由器/交换机）。

有一天，邮局爆满了，信件堆积如山。这时候你的新信件到了，邮局会怎么做？

1. **动作**：邮递员看了一眼满出来的信箱，直接把你的信**扔进了碎纸机**（丢包/Packet Drop）。
    
2. **后果**：
    
    - 你的朋友收不到信。
        
    - 你等了半天没收到回信，以为信丢了。
        
    - **最糟糕的是**：你不得不**重写一封信**再次寄出（重传）。这既浪费了你的时间，也浪费了纸张（带宽），而且你根本不知道为什么信丢了，可能还会继续拼命寄，导致邮局更堵。
        

**费曼直觉**：这就像你在嘈杂的派对上跟人说话。如果对方听不清（拥塞），他直接**无视你**。你只能一遍遍大喊，直到嗓子哑了。这是一种**“破坏性”**的沟通方式。

---

### 第二阶段：有 ECN 的“文明新时代” (ECN Marking)

工程师们觉得“直接扔信”太野蛮了，于是发明了 ECN。现在，同样的场景：

1. **场景**：邮局快满了（拥塞），但还没彻底塞爆。
    
2. **动作 (ECN 标记)**：邮递员**没有扔掉你的信**。相反，他在信封上盖了一个显眼的**红色印章**，上面写着：“**警告：邮局快堵死了！**”。
    
3. **传递**：邮递员把这封带着红色印章的信，成功送到了你朋友手中。
    
4. **反馈**：
    
    - 你朋友收到了信（数据没丢，不用重传！）。
        
    - 朋友看到红印章，在回信（ACK）里特意告诉你：“嘿，兄弟，收到了。但邮局说他们快忙疯了，你**寄慢一点**。”
        
5. **结果**：你收到了反馈，主动放慢了写信速度。邮局的压力缓解了，信也没丢。
    

**费曼直觉**：这就像在派对上，对方听不清时，不是无视你，而是**做了一个手势（比如把手放在耳边）**。你看到了手势，就懂了“哦，太吵了，我要说慢点”，但你们的对话并没有被打断。

这就是 **ECN（显式拥塞通知）** 的核心：**用“修改数据”代替“删除数据”来传达拥塞信号。**

---

### 第三阶段：深入微观——那个“红色印章”是什么？

现在我们把显微镜拿出来，看看在计算机网络里，这个“红色印章”到底长什么样。

还记得我们之前聊过的 `uint64_t` 吗？那是 64 个位。而 ECN 标记非常节省，它只用了 **IP 头部（Header）里的 2 个比特（Bit）**。

这两个比特就像邮局里的信号灯：

1. **`00` —— 不支持 ECN**
    
    - 意思：“我是老古董，我不懂什么叫标记。如果你堵了，就直接扔我的包吧。”
        
2. **`01` 或 `10` —— 支持 ECN (ECT)**
    
    - 意思：“我是支持 ECN 的新式信件。如果堵了，**请别扔，请标记我！**”
        
3. **`11` —— 遇到拥塞 (CE - Congestion Experienced)**
    
    - **这就是那个“红色印章”！**
        
    - 当交换机发现队列变长时，它不会丢包，而是把这两个比特改成 `11`。
        
    - 接收端看到 `11`，就知道：“哦！路堵了！”
        

---

### 第四阶段：结合 Uno 和 Phantom Queues

现在，让我们把这块拼图拼回你正在复现的 **Uno** 系统中。

你可能会问：“既然 ECN 这么好，为什么 Uno 还要搞个复杂的‘幻影队列’（Phantom Queue）？”

**这里有一个精妙的时间差：**

- **普通 ECN**：等到物理队列（真实的信箱）快满的时候才盖章。这时候，虽然没丢包，但信件已经在排队上浪费了很多时间（**高延迟**）。
    
- **Uno 的 ECN + 幻影队列**：
    
    - Uno 在物理队列**还是空的时候**，就通过“幻影队列”计算出“**未来可能会堵**”。
        
    - 它**提前**给信件盖上“红色印章”（ECN 标记）。
        
    - **结果**：发送端在物理队列真的堵塞之前就开始减速了。
        

**最终的费曼类比**：

- **无 ECN（丢包）**：车撞上墙了才知道路不通。
    
- **普通 ECN**：看到前面排长龙了，才开始踩刹车（虽然没撞，但堵在路上了）。
    
- **Uno (ECN + Phantom)**：导航软件（幻影队列）提前告诉你“前方2公里有拥堵趋势”，你在还没看到车流时就松开了油门。**结果你一路畅通无阻，几乎没有停顿。**
    


## Incast场景

我们将分三个阶段来拆解它：**字面拆解**、**必胜客惨案**、以及**为什么它被称为“吞吐量杀手”**。

---

### 第一阶段：字面拆解（它到底在干什么？）

首先，不要被这个词吓到。**Incast** 其实是两个词的组合：

- **In (向内)**：方向是汇聚的。
    
- **Cast (投送)**：像 Broadcast（广播，一对多）或 Multicast（组播，一对一组）。
    

Incast (Many-to-One)：就是**“多对一”**。

想象一个漏斗，很多股水流同时冲进来，但出口只有一个。

在数据中心里，这通常发生在**“搜索”**或**“计算”**任务结束时。

- **例子**：你在淘宝搜索“iPhone”。
    
- **后台**：这个请求被分发给 100 台服务器，每台服务器去搜索一部分数据库。
    
- **Incast 发生时刻**：这 100 台服务器几乎在**同一毫秒**完成了搜索，并同时把结果**扔回**给负责汇总的那一台服务器。
    

---

### 第二阶段：现实类比——“必胜客外卖惨案”

为了让你直观感受到 Incast 的破坏力，我们来构建一个场景。

**场景设置：**

- **你（接收端 Receiver）**：住在只有一扇窄门的公寓里，门口走廊（交换机缓存/Buffer）只能站 5 个人。
    
- **外卖员（发送端 Senders）**：100 个外卖小哥。
    
- **披萨（数据包 Packets）**：每个小哥手里拿两盒披萨。
    

正常情况（无 Incast）：

小哥们陆陆续续来，你开门、接披萨、关门。一切井然有序。

Incast 场景：

你搞了个大派对，你点了 100 份外卖。灾难发生了：这 100 个外卖小哥在同一秒钟冲到了你家门口。

1. **瓶颈 (Bottleneck)**：你的门一次只能过一个人（带宽限制）。
    
2. **溢出 (Buffer Overflow)**：走廊瞬间挤满了 5 个人，剩下的 95 个小哥根本挤不进来。
    
3. **丢包 (Packet Drop)**：那 95 个挤不进来的小哥，因为没地方站，直接**把披萨扔在地上走了**（物理队列满了，丢包）。
    
4. **超时 (Timeout)**：你发现披萨不够，给那 95 个小哥打电话。但小哥们很忙（TCP 超时机制），过了好久才接电话，然后慢吞吞地**重新送**一份过来。
    

**结果**：虽然你有能吃 100 个披萨的胃口（高带宽），但因为这一瞬间的拥堵，你实际上在前 10 分钟里只吃到了 5 个披萨。**效率（Goodput）几乎跌到了零。**

这就是 **Incast**：**并非总流量太大，而是瞬时并发太猛。**

---

### 第三阶段：为什么它是“吞吐量杀手”？（结合 Uno 的背景）

你正在复现的 Uno 论文 ，主要就是要解决这个问题。

在数据中心网络中，Incast 之所以致命，是因为两个技术细节的“恶性循环”：

1. 同步性 (Synchronization)：
    
    现在的服务器太快了。当一个任务（比如 AI 训练的梯度同步 2）分发下去，大家真的会在同一微秒做完。这就导致流量不是“细水长流”，而是“惊涛骇浪”。
    
2. 微突发 (Micro-bursts)：
    
    每个发送者发的数据可能不多（比如只是一个几 KB 的搜索结果）。
    
    - 因为数据少，**由于数据包太少，传统的 TCP 来不及建立“流速感”**，也来不及触发 ECN 减速。
        
    - 结果就是：大家都没减速，全速撞在了一起。
        
3. RTO (重传超时) 的惩罚：
    
    一旦发生 Incast 导致的丢包，发送端往往需要等待一个超时时间（RTO，通常是几毫秒到几百毫秒）才能重传。
    
    对于 Intra-DC（数据中心内）这种微秒级的环境，等待几毫秒就像是让法拉利去等红绿灯，性能直接崩盘 。
    

---

### 第四阶段：Uno 是如何拯救“外卖惨案”的？

现在你就能明白 Uno 设计的精妙之处了：

1. Phantom Queues（幻影队列）的作用：
    
    还记得那个“走廊”吗？幻影队列就像是在走廊还没满的时候，门卫（交换机）就拿起了大喇叭喊：“不管有没有挤满，现在人流量太大了，后面的人慢点跑！” 。
    
    - 它在物理走廊（Buffer）还没被塞爆之前，就提前感知到了 Incast 的形成趋势。
        
2. Quick Adapt（快速适应）的作用：
    
    当发送端（外卖小哥）听到大喇叭（收到 ECN），或者发现没人签收（ACK 变少）时，他不再是慢慢减速，而是直接急刹车（UnoCC 的 Quick Adapt 机制 5555）。
    
    - 这种剧烈的反应是为了瞬间腾出空间，让拥堵消散。
        

### 费曼式的最终总结

你可以这样向别人描述 **Incast**：

> “平时我们在高速公路上开车，虽然车多，但大家都在跑，这是**高带宽**。
> 
> **Incast** 就像是 100 辆法拉利在赛道上，发令枪一响，所有车都要在**同一秒钟**挤进**同一个单车道收费站**。
> 
> 结果就是发生了连环追尾（丢包）。虽然车速都很快，但大家都堵死在收费站门口动弹不得。Uno 做的，就是在收费站前 1 公里处放了感应器，提前告诉这些法拉利：‘前方即将汇聚，现在立刻减速！’”

理解了这个场景，你就理解了为什么你需要在仿真中测试 **"Incast Workload"** 以及为什么 **Phantom Queue** 如此重要了。

## 子流负载均衡

我们将分三个阶段来拆解：**“押运车困境”**、**“车队策略”**，以及**“智能变道”**。

---

### 第一阶段：旧时代的“押运车困境” (Single Path / ECMP)

在没有 UnoLB 之前，网络传输（特别是 ECMP，等价多路径路由）就像是**押运货物**。

**场景**：你要把 100 箱黄金（一个大数据块 Block）从北京运到上海。

1. **哈希碰撞 (Hash Collision) ——“死脑筋的调度员”**：
    
    - 现在的网络交换机通常使用“哈希算法”来选路。它看一眼你的车牌号（Flow ID / 五元组），然后说：“这辆车走京沪高速 A 线。”
        
    - 于是，你把这 100 箱黄金全部装进了**一辆大卡车**，开上了 A 线。
        
    - **风险**：万一 A 线发生了连环车祸（链路故障或严重拥塞），你的这辆大卡车就彻底堵死在那里了。你也无法换路，因为调度员认准了你的车牌号只能走 A 线 。
        
2. **结果**：整批黄金都迟到了。对于跨数据中心（Inter-DC）这种长距离传输，一旦堵车，代价极其昂贵（因为 RTT 太长，重传太慢）。
    

---

### 第二阶段：UnoLB 的“车队策略” (Subflow Splitting)

UnoLB 觉得“把鸡蛋放在一个篮子里”太蠢了。它决定采用**“子流” (Subflow)** 策略。

**新场景**：还是那 100 箱黄金。

1. 拆分 (Splitting)：
    
    UnoLB 不再租那一辆大卡车了。它租了 $n$ 辆小货车（比如 4 辆）。
    
    - 每辆车装 25 箱黄金。
        
    - 这每一辆小货车，就是一个 **“子流” (Subflow)**。
        
2. 分路 (Multipathing)：
    
    关键点来了！UnoLB 给这 4 辆小货车挂上了不同的“副车牌”（通过修改 UDP 源端口 Source Port 或 Flow Label）。
    
    - 调度员（交换机）看到不同的车牌，就会把它们分配到不同的路线上：
        
        - 1 号车走 A 线。
            
        - 2 号车走 B 线。
            
        - 3 号车走 C 线。
            
        - 4 号车走 D 线。
            
    - 这就是 **UnoLB (Uno Load Balancing)** 的核心：利用现代网络的多路径特性，把大流量拆散，并行传输 。
        

**费曼直觉**：这就像为了避免堵车，你和朋友们约好去同一个餐厅，大家分别开了 4 辆车，走了不同的导航路线。就算其中一条路堵了，其他 3 辆车也能按时到达。

---

### 第三阶段：“智能变道”与“丢车保帅” (Adaptive Rerouting & EC)

你可能会问：“要是 3 号车走的 C 线真的断了或者堵死了，那 25 箱黄金不还是丢了吗？”

这就是 UnoLB 最聪明的地方，它结合了 **纠删码 (Erasure Coding)** 和 **动态重路由**。

1. 纠删码 (Erasure Coding) ——“全息碎图”：
    
    还记得我们之前说的黄金吗？Uno 其实对黄金做了处理。
    
    - 它不是简单地把 100 箱黄金切分。它可能发出了 120 箱货物（100 箱是真金，20 箱是根据真金算出来的“校验箱”/Parity Packets）。
        
    - **魔法**：接收端只要收到任意 100 箱，就能还原出所有的黄金！
        
2. 配合 UnoLB：
    
    UnoLB 把这 120 箱货分散到那 4 辆车上 。
    
    - **情况 A**：3 号车在 C 线上翻车了（链路故障）。
        
    - **结果**：没关系！只要 1、2、4 号车到了，接收端凑够了箱子，黄金就能还原。**甚至不需要重传！** 
        
3. 动态重路由 (Adaptive Rerouting) ——“换个马甲”：
    
    如果 3 号车真的翻车了（超时 Timeout 或收到 NACK 报错），UnoLB 会意识到：“C 线好像断了” 。
    
    - **动作**：UnoLB 并不是傻傻地继续往 C 线发车。它会立刻给 3 号车**换一个新车牌**（改变 Source Port），或者把它并入到刚才成功抵达的 1 号车的路线上 。
        
    - **效果**：交换机看到新车牌，就把 3 号车（及其后续的货）指引到了通畅的 E 线上。
        

---

### 费曼式的最终总结

你可以这样向别人介绍 **UnoLB**：

> “以前的网络传输（ECMP）就像**开大巴车**。全班同学坐一辆车，遇到一条路堵死，全班都迟到。
> 
> **UnoLB** 就像是**组了一个车队**。
> 
> 1. **拆分**：它把全班同学分到了 4 辆小轿车里（子流）。
>     
> 2. **分路**：每辆车走不同的路（利用多路径）。
>     
> 3. **容错**：它还带了几个‘替补同学’（纠删码），就算有一辆车在路上抛锚了，剩下的人也足够完成任务。
>     
> 4. **智能**：一旦发现某条路抛锚，它会立刻通知后续车辆换一条路走（重路由）。
>     
> 
> 这样，无论网络中间哪条线断了，Uno 都能保证数据准时、完整地送达。”

现在，你理解为什么代码里会有 `subflow[index]` 和 `update_subflow(packet)` 这种逻辑了吗？这就是那个“给车队换路线”的过程。

## 不可靠连接
![[Pasted image 20251228195431.png]]
在不可靠连接（通常指 **UDP** 协议）中，数据包乱序到达（Out of Order）**绝对不会**导致整个数据流被丢弃。
### 1. 理解核心：什么是“不可靠连接”（UC / UDP）？
在计算机网络中，“不可靠连接”最典型的代表就是 **UDP (User Datagram Protocol，用户数据报协议)**。与之相对的是可靠连接 **TCP (Transmission Control Protocol)**。
要理解为什么乱序不会丢弃整个流，必须明白 UDP 的以下特性：
- **面向无连接 (Connectionless)：** 发送数据前不需要“握手”建立通道。想发就发。
- **面向数据报 (Datagram-oriented)：** 这是最关键的一点。UDP 把每个数据包看作是一个**独立的、完整的个体**（称为“数据报”）。每个数据报之间没有必然的依赖关系。
- **“尽力而为” (Best Effort)：** 协议只负责把数据报扔到网络上，至于它能不能到、什么时候到、按什么顺序到，UDP 协议本身完全不管。
### 2. 乱序时发生了什么？
想象你用快递给朋友寄了一套书，共三本（上、中、下册），你分别打了三个独立的包裹寄出。
- **TCP (可靠连接) 的做法：** 快递公司保证，无论包裹怎么走，送到你朋友手里时，必须是按顺序的（上、中、下）。如果“中册”在路上卡住了，“下册”先到了，快递员会拿着“下册”等你，直到“中册”到了，才一起给你。如果“中册”丢了，快递员会让你重新发一度“中册”，否则后面的都不给你。
- **UDP (不可靠连接) 的做法：** 快递公司只负责寄。朋友先收到了“下册”，然后收到了“上册”，最后才收到“中册”。

当使用不可靠连接（UDP）时，如果数据包 1、2、3 被发送，但接收端接收到的顺序是 1、3、2。
UDP 协议层的处理： UDP 接收端非常简单粗暴。它收到包 1，就立刻递交给上层应用；收到包 3，立刻递交给上层应用；收到包 2，立刻递交给上层应用。
结论： UDP 协议本身没有任何机制因为顺序错误而丢弃之前或之后的数据包。它只会忠实地、一个接一个地把收到的东西交上去。

- **不可靠连接（UDP）在发包前会给每个包 ID 吗？** **标准 UDP 协议本身：不会。** 标准的 UDP 报头（Header）非常简陋，里面**没有**专门用来标记顺序的“序列号（Sequence Number）”或“包 ID”字段。
- **该怎么理解 UC 中的乱序？** 乱序不是发送端故意“随机发”造成的，而是网络传输路径的不确定性造成的。因为 UDP 包没有序号，接收端的 UDP 协议栈根本**不知道**这些包原本的顺序应该是什么，所以它只能“来一个扔一个给上层”。
- **还是只切块然后随便发，也不排序呢？** 发送端通常是按顺序把切好的块扔进网络的，但协议不保证它们在网络中保持这个顺序，也不负责在接收端重新排序。