看AI Infra领域的论文时候，会发现如果匮乏LLM基础知识，会导致看论文或者看代码的时候产生疑惑。本篇笔记知识选自公主号Datawhale。
详细解释一下 Transformer 模型中的自注意力机制是如何工作的？它为什么比 RNN 更适合处理长序列
什么是位置编码？在 Transformer 中，为什么它是必需的？请列举两种实现方式。
你知道MHA，MQA，GQA的区别吗？详细解释一下。
请比较一下几种常见的 LLM 架构，例如 Encoder-Only, Decoder-Only, 和 Encoder-Decoder，并说明它们各自最擅长的任务类型。
什么是Scaling Laws？它揭示了模型性能、计算量和数据量之间的什么关系？这对LLM的研发有什么指导意义？
你觉得NLP和LLM最大的区别是什么？两者有何共同和不同之处？